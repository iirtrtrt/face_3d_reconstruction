{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e8a7faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoints in image 1: 5170\n",
      "Keypoints in image 2: 3579\n",
      "Number of matches before RANSAC: 1347\n",
      "Final number of point matches: 870\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load and preprocess images\n",
    "img1_left = cv.imread(\"samples/nb_front.png\", cv.IMREAD_GRAYSCALE)\n",
    "img2_left = cv.imread(\"samples/nb_left.png\", cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Create SIFT_left detector with custom parameters for more keypoints\n",
    "sift_left = cv.SIFT_create(\n",
    "    nfeatures=0,  # Maximum number of features (0 = unlimited)\n",
    "    nOctaveLayers=3,\n",
    "    contrastThreshold=0.002,  # Lower threshold = more keypoints (default is 0.04)\n",
    "    edgeThreshold=16,  # Higher threshold = more keypoints (default is 10)\n",
    "    sigma=1.2,\n",
    ")\n",
    "\n",
    "# find the keypoints and descriptors with SIFT_left\n",
    "kp1_left, des1_left = sift_left.detectAndCompute(img1_left, None)\n",
    "kp2_left, des2_left = sift_left.detectAndCompute(img2_left, None)\n",
    "\n",
    "print(f\"Keypoints in image 1: {len(kp1_left)}\")\n",
    "print(f\"Keypoints in image 2: {len(kp2_left)}\")\n",
    "\n",
    "# FLANN_left parameters - slightly modified for better performance\n",
    "FLANN_left_INDEX_KDTREE = 5\n",
    "index_params_left = dict(algorithm=FLANN_left_INDEX_KDTREE, trees=4)  # Increased from 5\n",
    "search_params_left = dict(checks=120)  # Increased from 50\n",
    "\n",
    "flann_left = cv.FlannBasedMatcher(index_params_left, search_params_left)\n",
    "\n",
    "# Cross-check matching for better results\n",
    "matches1to2_left = flann_left.knnMatch(des1_left, des2_left, k=2)\n",
    "matches2to1_left = flann_left.knnMatch(des2_left, des1_left, k=2)\n",
    "\n",
    "# Apply ratio test with a higher threshold (0.85 instead of 0.8)\n",
    "ratio_thresh_left = 0.88\n",
    "\n",
    "# First direction (1 to 2)\n",
    "good_matches1to2_left_left = []\n",
    "pts1_temp_left = []\n",
    "pts2_temp_left = []\n",
    "\n",
    "for i, (m, n) in enumerate(matches1to2_left):\n",
    "    if m.distance < ratio_thresh_left * n.distance:\n",
    "        good_matches1to2_left_left.append(m)\n",
    "        pts1_temp_left.append(kp1_left[m.queryIdx].pt)\n",
    "        pts2_temp_left.append(kp2_left[m.trainIdx].pt)\n",
    "\n",
    "good_matches2to1_left = []\n",
    "for i, (m, n) in enumerate(matches2to1_left):\n",
    "    if m.distance < ratio_thresh_left * n.distance:\n",
    "        good_matches2to1_left.append(m)\n",
    "\n",
    "pts1_left = pts1_temp_left\n",
    "pts2_left = pts2_temp_left\n",
    "\n",
    "pts1_left = np.int32(pts1_left)\n",
    "pts2_left = np.int32(pts2_left)\n",
    "\n",
    "print(f\"Number of matches before RANSAC: {len(pts1_left)}\")\n",
    "\n",
    "# Use RANSAC with a more lenient threshold to keep more matches\n",
    "F, mask = cv.findFundamentalMat(\n",
    "    pts1_left,\n",
    "    pts2_left,\n",
    "    method=cv.FM_RANSAC,\n",
    "    ransacReprojThreshold=20.0,  # Default is 3.0, higher = more matches\n",
    "    confidence=0.99,\n",
    ")  # Higher confidence = more iterations\n",
    "\n",
    "# We select only inlier points\n",
    "pts1_left = pts1_left[mask.ravel() == 1]\n",
    "pts2_left = pts2_left[mask.ravel() == 1]\n",
    "\n",
    "\n",
    "# Rest of your code remains the same\n",
    "def drawlines(img1_left, img2_left, lines, pts1_left, pts2_left):\n",
    "    r, c = img1_left.shape\n",
    "    img1_left = cv.cvtColor(img1_left, cv.COLOR_GRAY2BGR)\n",
    "    img2_left = cv.cvtColor(img2_left, cv.COLOR_GRAY2BGR)\n",
    "    for r, pt1, pt2 in zip(lines, pts1_left, pts2_left):\n",
    "        color = tuple(np.random.randint(0, 255, 3).tolist())\n",
    "        x0, y0 = map(int, [0, -r[2] / r[1]])\n",
    "        x1, y1 = map(int, [c, -(r[2] + r[0] * c) / r[1]])\n",
    "        img1_left = cv.line(img1_left, (x0, y0), (x1, y1), color, 1)\n",
    "        img1_left = cv.circle(img1_left, tuple(pt1), 5, color, -1)\n",
    "        img2_left = cv.circle(img2_left, tuple(pt2), 5, color, -1)\n",
    "    return img1_left, img2_left\n",
    "\n",
    "\n",
    "# Find epilines corresponding to points in right image and drawing lines on left image\n",
    "lines1 = cv.computeCorrespondEpilines(pts2_left.reshape(-1, 1, 2), 2, F)\n",
    "lines1 = lines1.reshape(-1, 3)\n",
    "img5_left, img6_left = drawlines(img1_left, img2_left, lines1, pts1_left, pts2_left)\n",
    "\n",
    "# Find epilines corresponding to points in left image and drawing lines on right image\n",
    "lines2 = cv.computeCorrespondEpilines(pts1_left.reshape(-1, 1, 2), 1, F)\n",
    "lines2 = lines2.reshape(-1, 3)\n",
    "img3_left, img4_left = drawlines(img2_left, img1_left, lines2, pts2_left, pts1_left)\n",
    "\n",
    "plt.figure(figsize=(30, 18))\n",
    "plt.subplot(121), plt.imshow(img5_left)\n",
    "plt.subplot(122), plt.imshow(img3_left)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final number of point matches: {len(pts1_left)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dc9f870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoints in image 1: 5170\n",
      "Keypoints in image 2: 3602\n",
      "Number of matches before RANSAC: 1341\n",
      "Final number of point matches: 884\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load and preprocess images\n",
    "img1_right = cv.imread(\"samples/nb_front.png\", cv.IMREAD_GRAYSCALE)\n",
    "img2_right = cv.imread(\"samples/nb_right.png\", cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Create SIFT_right detector with custom parameters for more keypoints\n",
    "sift_right = cv.SIFT_create(\n",
    "    nfeatures=0,  # Maximum number of features (0 = unlimited)\n",
    "    nOctaveLayers=3,\n",
    "    contrastThreshold=0.002,  # Lower threshold = more keypoints (default is 0.04)\n",
    "    edgeThreshold=16,  # Higher threshold = more keypoints (default is 10)\n",
    "    sigma=1.2,\n",
    ")\n",
    "\n",
    "# find the keypoints and descriptors with SIFT_right\n",
    "kp1_right, des1_right = sift_right.detectAndCompute(img1_right, None)\n",
    "kp2_right, des2_right = sift_right.detectAndCompute(img2_right, None)\n",
    "\n",
    "print(f\"Keypoints in image 1: {len(kp1_right)}\")\n",
    "print(f\"Keypoints in image 2: {len(kp2_right)}\")\n",
    "\n",
    "# FLANN_right parameters - slightly modified for better performance\n",
    "FLANN_right_INDEX_KDTREE = 5\n",
    "index_params_right = dict(\n",
    "    algorithm=FLANN_right_INDEX_KDTREE, trees=4\n",
    ")  # Increased from 5\n",
    "search_params_right = dict(checks=120)  # Increased from 50\n",
    "\n",
    "flann_right = cv.FlannBasedMatcher(index_params_right, search_params_right)\n",
    "\n",
    "# Cross-check matching for better results\n",
    "matches1to2_right = flann_right.knnMatch(des1_right, des2_right, k=2)\n",
    "matches2to1_right = flann_right.knnMatch(des2_right, des1_right, k=2)\n",
    "\n",
    "# Apply ratio test with a higher threshold (0.85 instead of 0.8)\n",
    "ratio_thresh_right = 0.88\n",
    "\n",
    "# First direction (1 to 2)\n",
    "good_matches1to2_right = []\n",
    "pts1_temp_right = []\n",
    "pts2_temp_right = []\n",
    "\n",
    "for i, (m, n) in enumerate(matches1to2_right):\n",
    "    if m.distance < ratio_thresh_right * n.distance:\n",
    "        good_matches1to2_right.append(m)\n",
    "        pts1_temp_right.append(kp1_right[m.queryIdx].pt)\n",
    "        pts2_temp_right.append(kp2_right[m.trainIdx].pt)\n",
    "\n",
    "good_matches2to1_right_right = []\n",
    "for i, (m, n) in enumerate(matches2to1_right):\n",
    "    if m.distance < ratio_thresh_right * n.distance:\n",
    "        good_matches2to1_right_right.append(m)\n",
    "\n",
    "pts1_right = pts1_temp_right\n",
    "pts2_right = pts2_temp_right\n",
    "\n",
    "pts1_right = np.int32(pts1_right)\n",
    "pts2_right = np.int32(pts2_right)\n",
    "\n",
    "print(f\"Number of matches before RANSAC: {len(pts1_right)}\")\n",
    "\n",
    "# Use RANSAC with a more lenient threshold to keep more matches\n",
    "F, mask = cv.findFundamentalMat(\n",
    "    pts1_right,\n",
    "    pts2_right,\n",
    "    method=cv.FM_RANSAC,\n",
    "    ransacReprojThreshold=20.0,  # Default is 3.0, higher = more matches\n",
    "    confidence=0.99,\n",
    ")  # Higher confidence = more iterations\n",
    "\n",
    "# We select only inlier points\n",
    "pts1_right = pts1_right[mask.ravel() == 1]\n",
    "pts2_right = pts2_right[mask.ravel() == 1]\n",
    "\n",
    "\n",
    "# Rest of your code remains the same\n",
    "def drawlines(img1_right, img2_right, lines, pts1_right, pts2_right):\n",
    "    r, c = img1_right.shape\n",
    "    img1_right = cv.cvtColor(img1_right, cv.COLOR_GRAY2BGR)\n",
    "    img2_right = cv.cvtColor(img2_right, cv.COLOR_GRAY2BGR)\n",
    "    for r, pt1, pt2 in zip(lines, pts1_right, pts2_right):\n",
    "        color = tuple(np.random.randint(0, 255, 3).tolist())\n",
    "        x0, y0 = map(int, [0, -r[2] / r[1]])\n",
    "        x1, y1 = map(int, [c, -(r[2] + r[0] * c) / r[1]])\n",
    "        img1_right = cv.line(img1_right, (x0, y0), (x1, y1), color, 1)\n",
    "        img1_right = cv.circle(img1_right, tuple(pt1), 5, color, -1)\n",
    "        img2_right = cv.circle(img2_right, tuple(pt2), 5, color, -1)\n",
    "    return img1_right, img2_right\n",
    "\n",
    "\n",
    "# Find epilines corresponding to points in right image and drawing lines on left image\n",
    "lines1 = cv.computeCorrespondEpilines(pts2_right.reshape(-1, 1, 2), 2, F)\n",
    "lines1 = lines1.reshape(-1, 3)\n",
    "img5_right, img6_right = drawlines(\n",
    "    img1_right, img2_right, lines1, pts1_right, pts2_right\n",
    ")\n",
    "\n",
    "# Find epilines corresponding to points in left image and drawing lines on right image\n",
    "lines2 = cv.computeCorrespondEpilines(pts1_right.reshape(-1, 1, 2), 1, F)\n",
    "lines2 = lines2.reshape(-1, 3)\n",
    "img3_right, img4_right = drawlines(\n",
    "    img2_right, img1_right, lines2, pts2_right, pts1_right\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(30, 18))\n",
    "plt.subplot(121), plt.imshow(img5_right)\n",
    "plt.subplot(122), plt.imshow(img3_right)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final number of point matches: {len(pts1_right)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fe8bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from math import sin, cos, radians\n",
    "\n",
    "\n",
    "def triangulate_3D_points(pts1, pts2, is_left=1):\n",
    "    # Camera parameters\n",
    "    focal_length_mm = 50\n",
    "    sensor_width_mm = 36\n",
    "    sensor_height_mm = 20.25\n",
    "    image_width_px = 1920\n",
    "    image_height_px = 1080\n",
    "\n",
    "    # Calculate focal lengths in pixels\n",
    "    fx = (focal_length_mm / sensor_width_mm) * image_width_px\n",
    "    fy = (focal_length_mm / sensor_height_mm) * image_height_px\n",
    "\n",
    "    # Principal point (assumed at image center)\n",
    "    cx = image_width_px / 2\n",
    "    cy = image_height_px / 2\n",
    "\n",
    "    # Intrinsic matrix\n",
    "    K = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "\n",
    "    if is_left:\n",
    "        # Extrinsic parameters\n",
    "        R1 = cv.Rodrigues(np.deg2rad([15, 0, 0]))[0]\n",
    "        t1 = np.array([[0], [0], [-1]])\n",
    "\n",
    "        R2 = cv.Rodrigues(np.deg2rad([-30, 0, 0]))[0]\n",
    "        t2 = np.array([[-0.5], [0], [-1]])\n",
    "    else:\n",
    "        R1 = cv.Rodrigues(np.deg2rad([-15, 0, 0]))[0]\n",
    "        t1 = np.array([[0], [0], [-1]])\n",
    "\n",
    "        R2 = cv.Rodrigues(np.deg2rad([30, 0, 0]))[0]\n",
    "        t2 = np.array([[0.5], [0], [-1]])\n",
    "\n",
    "    # Projection matrices\n",
    "    P1 = K @ np.hstack((R1, t1))\n",
    "    P2 = K @ np.hstack((R2, t2))\n",
    "\n",
    "    # Ensure matching number of points\n",
    "    pts1 = np.array(pts1, dtype=np.float32)\n",
    "    pts2 = np.array(pts2, dtype=np.float32)\n",
    "    if pts1.shape[0] != pts2.shape[0]:\n",
    "        raise ValueError(\"pts1 and pts2 must have the same number of points.\")\n",
    "\n",
    "    # Convert to homogeneous 2D\n",
    "    pts1_hom = cv.convertPointsToHomogeneous(pts1).reshape(-1, 3)\n",
    "    pts2_hom = cv.convertPointsToHomogeneous(pts2).reshape(-1, 3)\n",
    "\n",
    "    # Triangulate and convert to 3D\n",
    "    points_4D = cv.triangulatePoints(P1, P2, pts1_hom[:, :2].T, pts2_hom[:, :2].T)\n",
    "    points_3D = (points_4D[:3] / points_4D[3]).T  # shape (N, 3)\n",
    "\n",
    "    if is_left:\n",
    "        points_3D[:, 0] -= 0.25\n",
    "    else:\n",
    "        points_3D[:, 0] += 0.25\n",
    "\n",
    "    angle_deg = -22.5 if is_left else 22.5\n",
    "    # Define rotation angle (in degrees or radians)\n",
    "    theta = np.deg2rad(angle_deg)  # Replace with your desired angle\n",
    "\n",
    "    # Rotation matrix around y-axis\n",
    "    Ry = np.array(\n",
    "        [\n",
    "            [np.cos(theta), 0, np.sin(theta)],\n",
    "            [0, 1, 0],\n",
    "            [-np.sin(theta), 0, np.cos(theta)],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Apply rotation\n",
    "    points_3D = (Ry @ points_3D.T).T\n",
    "\n",
    "    return points_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6c342cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(870, 3)\n",
      "(884, 3)\n"
     ]
    }
   ],
   "source": [
    "points_3D_left = triangulate_3D_points(pts1_left, pts2_left, 1)\n",
    "points_3D_right = triangulate_3D_points(pts1_right, pts2_right, 0)\n",
    "\n",
    "print(points_3D_left.shape)\n",
    "print(points_3D_right.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6509d087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(832,)\n",
      "(850,)\n",
      "(0,)\n",
      "(1682, 3)\n"
     ]
    }
   ],
   "source": [
    "# Ensure C-contiguous arrays and flatten\n",
    "points_3D_left_contig = np.ascontiguousarray(points_3D_left).reshape(-1, 3)\n",
    "points_3D_right_contig = np.ascontiguousarray(points_3D_right).reshape(-1, 3)\n",
    "\n",
    "# Define structured dtype for 3D comparison\n",
    "dt3 = np.dtype(\n",
    "    [\n",
    "        (\"x\", points_3D_left.dtype),\n",
    "        (\"y\", points_3D_left.dtype),\n",
    "        (\"z\", points_3D_left.dtype),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# View as structured arrays\n",
    "left_structured = points_3D_left_contig.view(dt3).reshape(-1)\n",
    "right_structured = points_3D_right_contig.view(dt3).reshape(-1)\n",
    "\n",
    "# Find common and unique elements\n",
    "common = np.intersect1d(left_structured, right_structured)\n",
    "unique_left = np.setdiff1d(left_structured, common)\n",
    "unique_right = np.setdiff1d(right_structured, common)\n",
    "\n",
    "# Convert back to standard 3D arrays\n",
    "merged_structured = np.concatenate((unique_left, unique_right, common))\n",
    "merged_3D = merged_structured.view(points_3D_left.dtype).reshape(-1, 3)\n",
    "common_3D = common.view(points_3D_left.dtype).reshape(-1, 3)\n",
    "\n",
    "print(unique_left.shape)\n",
    "print(unique_right.shape)\n",
    "print(common.shape)\n",
    "print(merged_3D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a109bd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# merged_3D = merged_3D[merged_3D[:, 2] <= 0.08]\n",
    "# merged_3D = merged_3D[merged_3D[:, 2] >= 0]\n",
    "\n",
    "# # Plot only x and y (first two elements)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.scatter(merged_3D[:, 0], merged_3D[:, 1], c=\"green\", label=\"Common\", s=5)\n",
    "\n",
    "# plt.legend()\n",
    "# plt.xlabel(\"X\")\n",
    "# plt.ylabel(\"Y\")\n",
    "# plt.title(\"2D Projection of 3D Points\")\n",
    "# plt.grid(True)\n",
    "# plt.axis(\"equal\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "760261d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "# # Convert back to 3D arrays for plotting\n",
    "unique_left_3D = unique_left.view(points_3D_left.dtype).reshape(-1, 3)\n",
    "unique_right_3D = unique_right.view(points_3D_right.dtype).reshape(-1, 3)\n",
    "common_3D = common.view(points_3D_left.dtype).reshape(-1, 3)\n",
    "\n",
    "p3d = merged_3D\n",
    "p3d = p3d[p3d[:, 2] <= 0.04]\n",
    "p3d = p3d[p3d[:, 2] >= 0]\n",
    "\n",
    "# Create 3D figure\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter plot for 3D points\n",
    "ax.scatter(p3d[:, 0], p3d[:, 1], p3d[:, 2], c='green', label='Merged', s=5)\n",
    "\n",
    "# Labels and settings\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.set_title('3D Point Cloud')\n",
    "ax.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
