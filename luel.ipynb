{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece4fe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import least_squares\n",
    "import open3d as o3d\n",
    "import mediapipe as mp\n",
    "import json\n",
    "import trimesh  # For OBJ export\n",
    "\n",
    "# --- Load images ---\n",
    "img_front = cv2.imread(\"samples/nb_front.png\")\n",
    "img_left = cv2.imread(\"samples/nb_left.png\")\n",
    "img_right = cv2.imread(\"samples/nb_right.png\")\n",
    "img_front_gray = cv2.cvtColor(img_front, cv2.COLOR_BGR2GRAY)\n",
    "img_left_gray = cv2.cvtColor(img_left, cv2.COLOR_BGR2GRAY)\n",
    "img_right_gray = cv2.cvtColor(img_right, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "def get_sift_matches(img1, img2):\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    good_matches = []\n",
    "    pts1, pts2 = [], []\n",
    "\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.6 * n.distance:\n",
    "            good_matches.append(m)\n",
    "            pts1.append(kp1[m.queryIdx].pt)\n",
    "            pts2.append(kp2[m.trainIdx].pt)\n",
    "\n",
    "    return np.array(pts1, dtype=np.float32), np.array(pts2, dtype=np.float32)\n",
    "\n",
    "\n",
    "def load_camera_parameters(json_file):\n",
    "    with open(json_file, \"r\") as f:\n",
    "        cameras = json.load(f)\n",
    "\n",
    "    intrinsics_dict = {}\n",
    "    extrinsics_dict = {}\n",
    "    projection_matrices = {}\n",
    "\n",
    "    for cam in cameras:\n",
    "        name = cam[\"name\"]\n",
    "        K = np.array(cam[\"intrinsics\"])\n",
    "        R = np.array(cam[\"rotation\"])\n",
    "        t = np.array(cam[\"translation\"]).reshape((3, 1))\n",
    "        Rt = np.hstack((R, t))\n",
    "        P = K @ Rt\n",
    "\n",
    "        intrinsics_dict[name] = K\n",
    "        extrinsics_dict[name] = Rt\n",
    "        projection_matrices[name] = P\n",
    "\n",
    "    return intrinsics_dict, extrinsics_dict, projection_matrices\n",
    "\n",
    "\n",
    "def get_face_landmarks(img):\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    with mp_face_mesh.FaceMesh(\n",
    "        static_image_mode=True, refine_landmarks=True\n",
    "    ) as face_mesh:\n",
    "        results = face_mesh.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        if not results.multi_face_landmarks:\n",
    "            raise ValueError(\"No face landmarks detected.\")\n",
    "        h, w, _ = img.shape\n",
    "        landmarks = results.multi_face_landmarks[0].landmark\n",
    "        return np.array([[lm.x * w, lm.y * h] for lm in landmarks], dtype=np.float32)\n",
    "\n",
    "\n",
    "def triangulate_landmarks(P1, P2, pts1, pts2):\n",
    "    pts1 = pts1.T  # shape (2, N)\n",
    "    pts2 = pts2.T\n",
    "    pts4D = cv2.triangulatePoints(P1, P2, pts1, pts2)\n",
    "    pts3D = pts4D[:3] / pts4D[3]\n",
    "    return pts3D.T\n",
    "\n",
    "\n",
    "def save_point_cloud(pts3D, filename_prefix=\"output\"):\n",
    "    # Save as PLY\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(pts3D)\n",
    "\n",
    "    # Color coding (red for SIFT, blue for landmarks)\n",
    "    colors = np.zeros_like(pts3D)\n",
    "    if len(pts3D) == 1251:  # If combined\n",
    "        colors[:315] = [1, 0, 0]  # SIFT = red\n",
    "        colors[315:] = [0, 0, 1]  # Landmarks = blue\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    o3d.io.write_point_cloud(f\"{filename_prefix}.ply\", pcd)\n",
    "\n",
    "    # Save as OBJ using trimesh\n",
    "    mesh = trimesh.Trimesh(vertices=pts3D)\n",
    "    mesh.export(f\"{filename_prefix}.obj\")\n",
    "\n",
    "    # Visualize\n",
    "    o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "\n",
    "def reconstruct_face_mesh(pcd, filename_prefix=\"face_mesh\"):\n",
    "    # 1. Normalize point cloud scale\n",
    "    pts = np.asarray(pcd.points)\n",
    "    pts = (pts - np.min(pts)) / (np.max(pts) - np.min(pts))\n",
    "    pcd.points = o3d.utility.Vector3dVector(pts)\n",
    "\n",
    "    # 2. Compute normals (critical!)\n",
    "    pcd.estimate_normals(\n",
    "        search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30)\n",
    "    )\n",
    "    pcd.orient_normals_consistent_tangent_plane(k=30)\n",
    "\n",
    "    # 3. Poisson reconstruction with trimming\n",
    "    mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(\n",
    "        pcd, depth=9, width=0, scale=1.1, linear_fit=False\n",
    "    )\n",
    "    mesh = mesh.select_by_index(np.where(densities > np.quantile(densities, 0.25))[0])\n",
    "\n",
    "    # 4. Post-processing\n",
    "    mesh.compute_vertex_normals()\n",
    "    mesh = mesh.filter_smooth_taubin(number_of_iterations=10)\n",
    "    mesh.remove_degenerate_triangles()\n",
    "\n",
    "    # 5. Save\n",
    "    o3d.io.write_triangle_mesh(f\"{filename_prefix}.obj\", mesh)\n",
    "    o3d.io.write_triangle_mesh(f\"{filename_prefix}.ply\", mesh)\n",
    "    return mesh\n",
    "\n",
    "\n",
    "def colorize_point_cloud(pts3D, img, K, Rt):\n",
    "    pts_hom = np.hstack((pts3D, np.ones((pts3D.shape[0], 1))))\n",
    "    proj_pts = (K @ Rt @ pts_hom.T).T\n",
    "    proj_pts = proj_pts[:, :2] / proj_pts[:, 2, np.newaxis]\n",
    "\n",
    "    h, w, _ = img.shape\n",
    "    colors = []\n",
    "\n",
    "    for pt in proj_pts:\n",
    "        x, y = int(round(pt[0])), int(round(pt[1]))\n",
    "        if 0 <= x < w and 0 <= y < h:\n",
    "            color = img[y, x] / 255.0  # BGR to RGB, normalized\n",
    "            color = color[::-1]  # Convert BGR to RGB\n",
    "        else:\n",
    "            color = [0, 0, 0]\n",
    "        colors.append(color)\n",
    "\n",
    "    return np.array(colors)\n",
    "\n",
    "\n",
    "intrinsics, extrinsics, projection_matrices = load_camera_parameters(\n",
    "    \"samples/camera_parameters.json\"\n",
    ")\n",
    "\n",
    "# Get landmarks\n",
    "lm_front = get_face_landmarks(img_front)\n",
    "lm_left = get_face_landmarks(img_left)\n",
    "lm_right = get_face_landmarks(img_right)\n",
    "\n",
    "# Triangulate landmarks\n",
    "pts3D_L = triangulate_landmarks(\n",
    "    projection_matrices[\"Camera_Left\"],\n",
    "    projection_matrices[\"Camera_Front\"],\n",
    "    lm_left,\n",
    "    lm_front,\n",
    ")\n",
    "pts3D_R = triangulate_landmarks(\n",
    "    projection_matrices[\"Camera_Right\"],\n",
    "    projection_matrices[\"Camera_Front\"],\n",
    "    lm_right,\n",
    "    lm_front,\n",
    ")\n",
    "\n",
    "# Get SIFT matches\n",
    "sift_pts_L, sift_pts_F1 = get_sift_matches(img_left_gray, img_front_gray)\n",
    "sift_pts_R, sift_pts_F2 = get_sift_matches(img_right_gray, img_front_gray)\n",
    "\n",
    "# Triangulate SIFT matches\n",
    "F_L, mask_l = cv2.findFundamentalMat(\n",
    "    sift_pts_L, sift_pts_F1, cv2.FM_RANSAC, ransacReprojThreshold=2.0, confidence=0.95\n",
    ")\n",
    "sift_pts_L = sift_pts_L[mask_l.ravel() == 1]\n",
    "sift_pts_F1 = sift_pts_F1[mask_l.ravel() == 1]\n",
    "F_r, mask_r = cv2.findFundamentalMat(\n",
    "    sift_pts_R, sift_pts_F2, cv2.FM_RANSAC, ransacReprojThreshold=2.0, confidence=0.95\n",
    ")\n",
    "sift_pts_R = sift_pts_R[mask_r.ravel() == 1]\n",
    "sift_pts_F2 = sift_pts_F2[mask_r.ravel() == 1]\n",
    "\n",
    "pts3D_sift_LF = triangulate_landmarks(\n",
    "    projection_matrices[\"Camera_Left\"],\n",
    "    projection_matrices[\"Camera_Front\"],\n",
    "    sift_pts_L,\n",
    "    sift_pts_F1,\n",
    ")\n",
    "pts3D_sift_RF = triangulate_landmarks(\n",
    "    projection_matrices[\"Camera_Right\"],\n",
    "    projection_matrices[\"Camera_Front\"],\n",
    "    sift_pts_R,\n",
    "    sift_pts_F2,\n",
    ")\n",
    "\n",
    "# Combine all points\n",
    "\n",
    "pts3D_sift = np.vstack((pts3D_sift_LF, pts3D_sift_RF))\n",
    "pts3D_land = np.vstack((pts3D_L, pts3D_R))\n",
    "combined = np.vstack((pts3D_sift[:, :3], pts3D_land[:, :3])).astype(np.float64)\n",
    "\n",
    "# pcd = o3d.geometry.PointCloud()\n",
    "# pcd.points = o3d.utility.Vector3dVector(pts3D_land)\n",
    "# Convert to Open3D point cloud with colors from the front image\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(pts3D_land)\n",
    "colors = colorize_point_cloud(\n",
    "    pts3D_land, img_front, intrinsics[\"Camera_Front\"], extrinsics[\"Camera_Front\"]\n",
    ")\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "\n",
    "# mesh = reconstruct_face_mesh(pcd)\n",
    "# o3d.visualization.draw_geometries([mesh], mesh_show_back_face=True)\n",
    "\n",
    "mesh = reconstruct_face_mesh(pcd)\n",
    "o3d.visualization.draw_geometries([mesh])\n",
    "\n",
    "# face_mesh = reconstruct_face_mesh(combined, \"reconstructed_meshed_face\")\n",
    "\n",
    "# Visualize\n",
    "# o3d.visualization.draw_geometries([face_mesh])\n",
    "\n",
    "print(\n",
    "    f\"SIFT points: {pts3D_sift.shape}, Landmarks: {pts3D_land.shape}, Combined: {combined.shape}\"\n",
    ")\n",
    "\n",
    "# Save and visualize all versions\n",
    "save_point_cloud(pts3D_sift, \"sift_points\")\n",
    "save_point_cloud(pts3D_land, \"landmarks\")\n",
    "save_point_cloud(combined, \"combined_points\")\n",
    "\n",
    "# Additional quality checks\n",
    "print(\"First 3 SIFT points:\", pts3D_sift[:3])\n",
    "print(\"First 3 Landmarks:\", pts3D_land[:3])\n",
    "print(\"NaN values:\", np.isnan(combined).sum())\n",
    "print(\"Inf values:\", np.isinf(combined).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "129f3081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Front-Left points: 478\n",
      "Matched Front-Right points: 363\n",
      "Inlier Front-Left matches: 279\n",
      "Inlier Front-Right matches: 171\n",
      "-Right rotation:  [[ 8.79549157e-01  6.73968132e-03 -4.75760293e-01]\n",
      " [-5.48580285e-03  9.99976856e-01  4.02406861e-03]\n",
      " [ 4.75776403e-01 -9.29438979e-04  8.79565774e-01]]\n",
      "PLY file saved as 'reconstructed.ply' with 450 points.\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "Generated 217559 3D points\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "Saved both point cloud and mesh\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'open3d.cpu.pybind.visualization.ViewControl' object has no attribute 'fit_bounds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 407\u001b[0m\n\u001b[1;32m    405\u001b[0m ctr \u001b[38;5;241m=\u001b[39m vis\u001b[38;5;241m.\u001b[39mget_view_control()\n\u001b[1;32m    406\u001b[0m bbox \u001b[38;5;241m=\u001b[39m pcl_dense\u001b[38;5;241m.\u001b[39mget_axis_aligned_bounding_box()\n\u001b[0;32m--> 407\u001b[0m \u001b[43mctr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_bounds\u001b[49m(bbox\u001b[38;5;241m.\u001b[39mget_min_bound(), bbox\u001b[38;5;241m.\u001b[39mget_max_bound())\n\u001b[1;32m    409\u001b[0m vis\u001b[38;5;241m.\u001b[39mpoll_events()\n\u001b[1;32m    410\u001b[0m vis\u001b[38;5;241m.\u001b[39mupdate_renderer()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'open3d.cpu.pybind.visualization.ViewControl' object has no attribute 'fit_bounds'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import least_squares\n",
    "import open3d as o3d\n",
    "\n",
    "# --- Load images ---\n",
    "img_front = cv2.imread(\"samples/Camera_Front.png\")\n",
    "img_left = cv2.imread(\"samples/Camera_Left.png\")\n",
    "img_right = cv2.imread(\"samples/Camera_Right.png\")\n",
    "img_front_gray = cv2.cvtColor(img_front, cv2.COLOR_BGR2GRAY)\n",
    "img_left_gray = cv2.cvtColor(img_left, cv2.COLOR_BGR2GRAY)\n",
    "img_right_gray = cv2.cvtColor(img_right, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# --- Camera intrinsic matrix (assumed known) ---\n",
    "# Camera intrinsics\n",
    "focal_length_mm = 50\n",
    "sensor_width_mm = 36\n",
    "image_width_px = 1920\n",
    "image_height_px = 1080\n",
    "\n",
    "# Calculate focal length in pixels\n",
    "focal_length_px = (focal_length_mm / sensor_width_mm) * image_width_px\n",
    "\n",
    "# Camera intrinsics matrix\n",
    "K = np.array(\n",
    "    [\n",
    "        [2666.666666666667, 0, 960],\n",
    "        [0, 2250, 540],\n",
    "        [0, 0, 1],\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# --- Feature detection & matching function ---\n",
    "def match_features(img1_gray, img2_gray):\n",
    "    # Initialize SIFT detector\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp1, desc1 = sift.detectAndCompute(img1_gray, None)\n",
    "    kp2, desc2 = sift.detectAndCompute(img2_gray, None)\n",
    "\n",
    "    # FLANN parameters for SIFT\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=9)\n",
    "    search_params = dict(checks=50)  # Higher = more accurate but slower\n",
    "\n",
    "    # Initialize FLANN matcher\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    # Perform KNN matching\n",
    "    matches = flann.knnMatch(desc1, desc2, k=2)\n",
    "\n",
    "    # Apply Lowe's ratio test\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.88 * n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    # Extract matched keypoints\n",
    "    pts1 = np.float32([kp1[m.queryIdx].pt for m in good])\n",
    "    pts2 = np.float32([kp2[m.trainIdx].pt for m in good])\n",
    "\n",
    "    return pts1, pts2\n",
    "\n",
    "\n",
    "# --- Match Front-Left and Front-Right ---\n",
    "pts_front_l, pts_left = match_features(img_front_gray, img_left_gray)\n",
    "pts_front_r, pts_right = match_features(img_front_gray, img_right_gray)\n",
    "\n",
    "print(f\"Matched Front-Left points: {len(pts_front_l)}\")\n",
    "print(f\"Matched Front-Right points: {len(pts_front_r)}\")\n",
    "\n",
    "\n",
    "# --- Epipolar lines drawing ---\n",
    "def draw_epilines(img1, img2, pts1, pts2, F):\n",
    "    h, w = img1.shape[:2]\n",
    "    lines = cv2.computeCorrespondEpilines(pts2.reshape(-1, 1, 2), 2, F)\n",
    "    lines = lines.reshape(-1, 3)\n",
    "    img1_epi = img1.copy()\n",
    "    for r, pt in zip(lines, pts1):\n",
    "        color = tuple(np.random.randint(0, 255, 3).tolist())\n",
    "        if r[1] != 0:\n",
    "            x0, y0 = map(int, [0, -r[2] / r[1]])\n",
    "            x1, y1 = map(int, [w, -(r[2] + r[0] * w) / r[1]])\n",
    "            cv2.line(img1_epi, (x0, y0), (x1, y1), color, 1)\n",
    "        cv2.circle(img1_epi, tuple(map(int, pt)), 4, color, -1)\n",
    "    return img1_epi\n",
    "\n",
    "\n",
    "# --- Fundamental Matrices ---\n",
    "F_l, mask_l = cv2.findFundamentalMat(pts_front_l, pts_left, cv2.FM_RANSAC)\n",
    "F_r, mask_r = cv2.findFundamentalMat(pts_front_r, pts_right, cv2.FM_RANSAC)\n",
    "\n",
    "# Filter inliers\n",
    "pts_front_l, pts_left = pts_front_l[mask_l.ravel() == 1], pts_left[mask_l.ravel() == 1]\n",
    "pts_front_r, pts_right = (\n",
    "    pts_front_r[mask_r.ravel() == 1],\n",
    "    pts_right[mask_r.ravel() == 1],\n",
    ")\n",
    "\n",
    "print(f\"Inlier Front-Left matches: {len(pts_front_l)}\")\n",
    "print(f\"Inlier Front-Right matches: {len(pts_front_r)}\")\n",
    "\n",
    "# --- Draw epipolar lines ---\n",
    "front_left_epi = draw_epilines(img_front, img_left, pts_front_l, pts_left, F_l)\n",
    "left_epi = draw_epilines(img_left, img_front, pts_left, pts_front_l, F_l.T)\n",
    "front_right_epi = draw_epilines(img_front, img_right, pts_front_r, pts_right, F_r)\n",
    "right_epi = draw_epilines(img_right, img_front, pts_right, pts_front_r, F_r.T)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.subplot(221), plt.imshow(\n",
    "    cv2.cvtColor(front_left_epi, cv2.COLOR_BGR2RGB)\n",
    "), plt.title(\"Front Epilines - Left\"), plt.axis(\"off\")\n",
    "plt.subplot(222), plt.imshow(cv2.cvtColor(left_epi, cv2.COLOR_BGR2RGB)), plt.title(\n",
    "    \"Left Epilines\"\n",
    "), plt.axis(\"off\")\n",
    "plt.subplot(223), plt.imshow(\n",
    "    cv2.cvtColor(front_right_epi, cv2.COLOR_BGR2RGB)\n",
    "), plt.title(\"Front Epilines - Right\"), plt.axis(\"off\")\n",
    "plt.subplot(224), plt.imshow(cv2.cvtColor(right_epi, cv2.COLOR_BGR2RGB)), plt.title(\n",
    "    \"Right Epilines\"\n",
    "), plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output_plot.png\")  # Saves the plot as an image file\n",
    "plt.close()  # Clears the figure to free memory\n",
    "# plt.show()\n",
    "\n",
    "# --- Triangulation ---\n",
    "E_l = K.T @ F_l @ K\n",
    "_, R_l, t_l, _ = cv2.recoverPose(E_l, pts_front_l, pts_left, K)\n",
    "\n",
    "E_r = K.T @ F_r @ K\n",
    "_, R_r, t_r, _ = cv2.recoverPose(E_r, pts_front_r, pts_right, K)\n",
    "print(f\"-Right rotation: \", R_l)\n",
    "P0 = K @ np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "P_l = K @ np.hstack((R_l, t_l))\n",
    "P_r = K @ np.hstack((R_r, t_r))\n",
    "\n",
    "pts4D_l = cv2.triangulatePoints(P0, P_l, pts_front_l.T, pts_left.T)\n",
    "pts4D_r = cv2.triangulatePoints(P0, P_r, pts_front_r.T, pts_right.T)\n",
    "\n",
    "pts3D_l = (pts4D_l[:3] / pts4D_l[3]).T\n",
    "pts3D_r = (pts4D_r[:3] / pts4D_r[3]).T\n",
    "pts3D = np.vstack((pts3D_l, pts3D_r))\n",
    "\n",
    "\n",
    "# --- Optional: Bundle Adjustment ---\n",
    "def reprojection_error(params, pts_3d, pts_2d, K):\n",
    "    rvec = params[:3].astype(np.float64)\n",
    "    tvec = params[3:6].astype(np.float64)\n",
    "    proj_pts, _ = cv2.projectPoints(pts_3d.astype(np.float64), rvec, tvec, K, None)\n",
    "    return (proj_pts.squeeze() - pts_2d).ravel()\n",
    "\n",
    "\n",
    "init_params = np.zeros(6)\n",
    "ba_result = least_squares(reprojection_error, init_params, args=(pts3D_l, pts_left, K))\n",
    "\n",
    "\n",
    "# --- Reprojection Visualization ---\n",
    "def plot_reprojection(pts_actual, pts_reproj, title):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(pts_actual[:, 0], pts_actual[:, 1], c=\"blue\", label=\"Actual 2D Points\")\n",
    "    plt.scatter(\n",
    "        pts_reproj[:, 0],\n",
    "        pts_reproj[:, 1],\n",
    "        c=\"red\",\n",
    "        marker=\"+\",\n",
    "        label=\"Reprojected Points\",\n",
    "    )\n",
    "    for i in range(len(pts_actual)):\n",
    "        plt.plot(\n",
    "            [pts_actual[i, 0], pts_reproj[i, 0]],\n",
    "            [pts_actual[i, 1], pts_reproj[i, 1]],\n",
    "            \"gray\",\n",
    "            linewidth=0.5,\n",
    "        )\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"output_projection.png\")\n",
    "    # Saves the plot as an image file\n",
    "    plt.close()  # Clears the figure to free memory\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "rvec_opt = ba_result.x[:3]\n",
    "tvec_opt = ba_result.x[3:6]\n",
    "pts2d_reproj, _ = cv2.projectPoints(\n",
    "    pts3D_l.astype(np.float64), rvec_opt, tvec_opt, K, None\n",
    ")\n",
    "pts2d_reproj = pts2d_reproj.squeeze()\n",
    "plot_reprojection(pts_left, pts2d_reproj, \"Reprojection vs Actual (Left View)\")\n",
    "\n",
    "\n",
    "# --- Save as PLY file ---\n",
    "def save_to_ply(filename, points):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"ply\\nformat ascii 1.0\\nelement vertex {}\\n\".format(len(points)))\n",
    "        f.write(\"property float x\\nproperty float y\\nproperty float z\\nend_header\\n\")\n",
    "        for p in points:\n",
    "            f.write(\"{} {} {}\\n\".format(p[0], p[1], p[2]))\n",
    "\n",
    "\n",
    "save_to_ply(\"reconstructed.ply\", pts3D)\n",
    "print(\"PLY file saved as 'reconstructed.ply' with {} points.\".format(len(pts3D)))\n",
    "\n",
    "# --- Visualize with Open3D (sparse) ---\n",
    "pcl = o3d.geometry.PointCloud()\n",
    "pcl.points = o3d.utility.Vector3dVector(pts3D)\n",
    "\n",
    "\n",
    "# --- Add camera frustums ---\n",
    "def create_camera_frustum(scale=0.3, color=[1, 0, 0], line_width=2.0):\n",
    "    \"\"\"Create a compact camera frustum visualization\n",
    "\n",
    "    Args:\n",
    "        scale: Size of the frustum (default 0.3 is good for face reconstruction)\n",
    "        color: RGB color of the frustum lines\n",
    "        line_width: Visual thickness of the lines\n",
    "\n",
    "    Returns:\n",
    "        Open3D LineSet representing the camera frustum\n",
    "    \"\"\"\n",
    "    frustum = o3d.geometry.LineSet()\n",
    "\n",
    "    # More compact pyramid geometry (base is now closer to apex)\n",
    "    points = (\n",
    "        np.array(\n",
    "            [\n",
    "                [0, 0, 0],  # Apex (camera center)\n",
    "                [0.5, 0.5, 1],  # Top-right\n",
    "                [-0.5, 0.5, 1],  # Top-left\n",
    "                [-0.5, -0.5, 1],  # Bottom-left\n",
    "                [0.5, -0.5, 1],  # Bottom-right\n",
    "            ]\n",
    "        )\n",
    "        * scale\n",
    "    )\n",
    "\n",
    "    # Pyramid edges\n",
    "    lines = [\n",
    "        [0, 1],\n",
    "        [0, 2],\n",
    "        [0, 3],\n",
    "        [0, 4],  # Apex to corners\n",
    "        [1, 2],\n",
    "        [2, 3],\n",
    "        [3, 4],\n",
    "        [4, 1],  # Base rectangle\n",
    "    ]\n",
    "\n",
    "    frustum.points = o3d.utility.Vector3dVector(points)\n",
    "    frustum.lines = o3d.utility.Vector2iVector(lines)\n",
    "\n",
    "    # Make lines more visible\n",
    "    frustum.paint_uniform_color(color)\n",
    "\n",
    "    # For Open3D versions that support line width\n",
    "    if hasattr(frustum, \"line_width\"):\n",
    "        frustum.line_width = line_width\n",
    "\n",
    "    return frustum\n",
    "\n",
    "\n",
    "# Create smaller frustums (scale=0.3 instead of 5)\n",
    "camera_front = create_camera_frustum(scale=0.3, color=[1, 0, 0])  # Red\n",
    "camera_left = create_camera_frustum(scale=0.3, color=[0, 1, 0])  # Green\n",
    "camera_right = create_camera_frustum(scale=0.3, color=[0, 0, 1])  # Blue\n",
    "\n",
    "# Apply camera poses\n",
    "T_left = np.eye(4)\n",
    "T_left[:3, :3] = R_l\n",
    "T_left[:3, 3] = t_l.ravel()\n",
    "camera_left = camera_left.transform(T_left)\n",
    "\n",
    "T_right = np.eye(4)\n",
    "T_right[:3, :3] = R_r\n",
    "T_right[:3, 3] = t_r.ravel()\n",
    "camera_right = camera_right.transform(T_right)\n",
    "\n",
    "# Visualize with better viewing parameters\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window(\n",
    "    width=800, height=600, window_name=\"3D Face Reconstruction with Camera Frustums\"\n",
    ")\n",
    "\n",
    "# Add geometries\n",
    "vis.add_geometry(pcl)\n",
    "vis.add_geometry(camera_front)\n",
    "vis.add_geometry(camera_left)\n",
    "vis.add_geometry(camera_right)\n",
    "\n",
    "# Set better viewing angle\n",
    "ctrl = vis.get_view_control()\n",
    "ctrl.set_front([0, 0, -1])  # Looking along negative z-axis\n",
    "ctrl.set_up([0, -1, 0])  # Y-axis is up\n",
    "ctrl.set_zoom(0.8)  # Slightly zoomed out\n",
    "\n",
    "# Custom rendering options\n",
    "opt = vis.get_render_option()\n",
    "opt.background_color = np.array([0.9, 0.9, 0.9])  # Light gray background\n",
    "opt.light_on = True\n",
    "\n",
    "vis.run()\n",
    "vis.destroy_window()\n",
    "\n",
    "# --- Dense Stereo Matching ---\n",
    "\n",
    "# Define stereo matcher\n",
    "stereo = cv2.StereoSGBM_create(\n",
    "    minDisparity=0,\n",
    "    numDisparities=192,\n",
    "    blockSize=5,\n",
    "    P1=8 * 3 * 5**2,\n",
    "    P2=32 * 3 * 5**2,\n",
    "    disp12MaxDiff=5,\n",
    "    uniquenessRatio=15,\n",
    "    speckleWindowSize=50,\n",
    "    speckleRange=32,\n",
    ")\n",
    "\n",
    "# Compute disparity for front-right\n",
    "disp_fr = stereo.compute(img_front_gray, img_right_gray).astype(np.float32) / 16.0\n",
    "# Compute disparity for front-left\n",
    "disp_fl = stereo.compute(img_front_gray, img_left_gray).astype(np.float32) / 16.0\n",
    "\n",
    "# Display disparity maps\n",
    "plt.figure()\n",
    "plt.imshow(disp_fr, cmap=\"jet\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Disparity Map Front-Right\")\n",
    "plt.savefig(\"disparity_map_fr.png\")\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(disp_fl, cmap=\"jet\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Disparity Map Front-Left\")\n",
    "plt.savefig(\"disparity_map_fl.png\")\n",
    "plt.close()\n",
    "\n",
    "# Camera intrinsics (dummy values - replace with calibration data)\n",
    "\n",
    "\n",
    "# Reprojection matrix\n",
    "h, w = img_front_gray.shape\n",
    "Q = np.float32(\n",
    "    [[1, 0, 0, -K[0, 2]], [0, -1, 0, K[1, 2]], [0, 0, 0, K[0, 0]], [0, 0, 1, 0]]\n",
    ")\n",
    "\n",
    "# Reproject to 3D for both\n",
    "points_3d_fr = cv2.reprojectImageTo3D(disp_fr, Q)\n",
    "points_3d_fl = cv2.reprojectImageTo3D(disp_fl, Q)\n",
    "colors_fr = cv2.cvtColor(img_front, cv2.COLOR_BGR2RGB)\n",
    "colors_fl = cv2.cvtColor(img_front, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "mask_fr = (disp_fr > disp_fr.min()) & (points_3d_fr[:, :, 2] < 1000)\n",
    "mask_fl = (disp_fl > disp_fl.min()) & (points_3d_fl[:, :, 2] < 1000)\n",
    "\n",
    "out_points_fr = points_3d_fr[mask_fr]\n",
    "out_colors_fr = colors_fr[mask_fr]\n",
    "out_points_fl = points_3d_fl[mask_fl]\n",
    "out_colors_fl = colors_fl[mask_fl]\n",
    "\n",
    "# Merge point clouds\n",
    "all_points = np.vstack((out_points_fr, out_points_fl))\n",
    "all_colors = np.vstack((out_colors_fr, out_colors_fl))\n",
    "\n",
    "print(f\"Generated {len(all_points)} 3D points\")\n",
    "\n",
    "# Create point cloud\n",
    "pcl_dense = o3d.geometry.PointCloud()\n",
    "pcl_dense.points = o3d.utility.Vector3dVector(all_points)\n",
    "pcl_dense.colors = o3d.utility.Vector3dVector(all_colors / 255.0)\n",
    "\n",
    "# Visualize dense point cloud\n",
    "o3d.visualization.draw_geometries(\n",
    "    [pcl_dense],\n",
    "    window_name=\"Dense 3D Reconstruction\",\n",
    "    width=800,\n",
    "    height=600,\n",
    "    point_show_normal=False,\n",
    ")\n",
    "\n",
    "# Mesh generation\n",
    "pcl_dense.estimate_normals()\n",
    "mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(\n",
    "    pcl_dense, depth=7\n",
    ")\n",
    "mesh.remove_vertices_by_mask(densities < np.quantile(densities, 0.1))\n",
    "o3d.visualization.draw_geometries([mesh], window_name=\"Combined Mesh\")\n",
    "\n",
    "# Save outputs\n",
    "o3d.io.write_point_cloud(\"dense_reconstruction.ply\", pcl_dense)\n",
    "o3d.io.write_triangle_mesh(\"dense_mesh.obj\", mesh)\n",
    "print(\"Saved both point cloud and mesh\")\n",
    "\n",
    "# Create 2D frontal projection\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window(width=w, height=h)\n",
    "vis.add_geometry(pcl_dense)\n",
    "ctr = vis.get_view_control()\n",
    "bbox = pcl_dense.get_axis_aligned_bounding_box()\n",
    "ctr.fit_bounds(bbox.get_min_bound(), bbox.get_max_bound())\n",
    "\n",
    "vis.poll_events()\n",
    "vis.update_renderer()\n",
    "vis.capture_screen_image(\"frontal_view.png\", do_render=True)\n",
    "vis.destroy_window()\n",
    "print(\"Saved frontal view as 'frontal_view.png'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
